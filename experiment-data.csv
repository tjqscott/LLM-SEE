Primary,Year,Title,doi,Scope,Goal,Type,Subject Design,Granularity,Cognitive Bias,Measurement,Experiment Count,Participants per treatment,Treatment count,Treatments,Effect Size Magnitude,Effect Size Measurement,Participant Profile,Total Participants,Hypotheses,Statistical tests,Antipatterns,Essential,Desirable,Extraordinary
Abdel-Hamid,1993,Software Project Control: An Experimental Investigation of Judgment with Fallible Information,https://doi.org/10.1109/32.232025,Software project control and managerial judgment under conditions of unreliable information.,To investigate the heuristics managers use to assess project productivity when faced with poor initial estimates and unreliable status reports.,Case Study,Between-subjects,Project level,Anchoring,Estimated effort,1,9-10,3,"Low, Med, High anchor",N/A,,Grad Students CS management,28,Productivity estimates will be significantly influenced by the initial anchor provided and will not converge to the actual value over time.,Multivariate Analysis of Variance (MANOVA) for repeated measures; t-test.,Mismatched Design and Context (students are used in place of managers),16,5,0
Aranda,2005,Anchoring and Adjustment in Software Estimation,https://doi.org/10.1145/1095430.1081761,Project effort estimation with anchoring manipulation,"Test is anchoring affects estimates, experiance and confidence intervels compensate",Controlled,Between-subjects,Project level,Anchoring,Effort estimates & Confidence interva;s,1,6-9,3,"High, Med, Low anchor",N/A,,Grad students & professionals,23,No difference between estimates; no difference between max(low) and min(high),T-tests,"Unjustified Design Choice (No random assignment) Mismatched Design and Context (sample size, Unbalanced design, volunteers)",13,4,0
Connolly,1997,Decomposed Versus Holistic Estimates of Effort Required for Software Writing,https://doi.org/10.1287/mnsc.43.7.1029,The effect of task decomposition on work-time estimates for software writing tasks.,"To test if decomposing a task improves the accuracy and calibration of effort estimates, and to evaluate other de-biasing interventions.",Controlled,Between-subjects,Project level; Task level,Over-confidence; Over-optimism,"Estimated effort, Actual effort",2,7-14,2-4,"Task decomp. question wording, question order, training, extreme limit setting",N/A,,Advanced Undergrad programmers,59,Estimates are overtight; decomposition has little effect on overtightness; an extreme-limit-setting exercise will reduce overtightness.,Chi-squared tests.,Unjustified Design Choice (limit-setting is tested between experiments),17,4,1
Goswami,2020,"More time, more work: How time limits bias estimates of task scope and project duration",https://doi.org/10.1017/S1930297500008196,Investigation into the effect of time limits on external effort predictions,To demonstrate a bias on completion estimates based on a time limit,Controlled,Between-subjects,Project level,Time limit bias,Effort estimate; accuracy,5,50-203,2-4,5min vs 15min,Large,cohen's d=1.247,"Online, students, pro managers",1943,People estimate longer completion times for tasks with longer time limits,"ANOVA, t-test, hierarchical regression",None,17,8,3
Haugen,2006,An Empirical Study of Using Planning Poker for User Story Estimation,https://doi.org/10.1109/AGILE.2006.16,Group estimation of user stories in Extreme Programming (XP).,To empirically examine if introducing the Planning Poker process improves estimation performance compared to unstructured group estimation.,Case Study,Between-subjects,Task level,Anchoring,Relative error; magnitude,1,7-11,2,"Unstructured, Planning Poker",N/A,,Experienced developers,18,Introducing Planning Poker will improve the team's estimation performance.,"Descriptive statistics (mean, median) and data visualization (box plot). No inferential tests were reported.",Unjustified Design Choice (Not a controlled experiment) Mismatched Design and Context (Learning effect and team changes),10,3,0
Jørgensen,2005,Industrial Use of Formal Software Cost Estimation Models: Expert Estimation in Disguise?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gxqbS9AAAAAJ&cstart=100&pagesize=100&citation_for_view=gxqbS9AAAAAJ:PR6Y55bgFSsC,The industrial application of formal software cost estimation models.,"To test the hypothesis that formal estimation models are often heavily influenced by expert judgment, becoming ""expert estimation in disguise.""",Case study,Between-subjects,Project level,Anchoring,Human Function Point effort; Machine Function Point effort,1,N/A,2,Actual estimate vs. New machine estimate,N/A,,Five real projects,5,Formal software cost estimates are frequently and strongly influenced by expert judgment.,None,Poorly Defined Variables (from vague hypothesis) Mismatched Design and Context (only five projects means weak evidence),8,2,0
Jørgensen,2001,Software Process Improvement and Human Judgement Heuristics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gxqbS9AAAAAJ&cstart=20&pagesize=80&citation_for_view=gxqbS9AAAAAJ:Zph67rFs4hoC,"The application of human judgment heuristics to software process improvement, particularly effort estimation.",To exemplify how knowledge of heuristics can improve software processes and to evaluate the use of the representativeness heuristic.,Discussion,Between-subjects,Project level,Anchoring,Estimated productivity,1,5-17,4,Strategy,N/A,,Undergrad CS Students,38,The paper aims to illustrate that the use of the representativeness heuristic varies widely and is not always based on an awareness of estimation uncertainty.,Descriptive statistics,"Mismatched Design and Context (only stidents used, small illustrative experiment)",10,2,0
Jørgensen,2002,Better sure than safe? Over-confidence in judgement based software development effort prediction intervals,https://doi.org/10.1016/S0164-1212(02)00160-7,Over-confidence in judgment-based prediction intervals (PIs) for software development effort.,To assess the accuracy of effort PIs in real projects and to understand the reasons for the observed over-confidence.,Controlled; Case study,Between-subjects,Project level,Over-confidence,Hit Rate; Interval Width; Accuracy; Relative effort,4,4-37,2-5,Pros vs. students; individual vs. team; cofidence levels; behaviors,N/A,,"Pro developers, managers; students",162,"PIs are generally over-confident (too narrow); the paper explores reasons related to experience, interpretation of ""confidence,"" and feedback mechanisms.","Descriptive statistics (hit rate, median, mean); Correlation.","Mismatched Design and Context (Artificial experiment, minimal industrial data)",15,4,2
Jørgensen,2006,Prediction of Overoptimistic Predictions,https://doi.org/10.14236/ewic/EASE2006.5,Using general psychological tests of optimism to predict overoptimistic performance predictions in software engineering.,To test if standard optimism tests (ASQ and LOT-R) correlate with optimistic predictions well enough to be used for selecting realistic estimators.,Correlational,Between-subjects,Project level,Over-optimism,Optimism score; prediction accuracy,2,14-25,N/A,Optimistic vs. Pessimistic,Weak,corelation r = -0.17,Students/ Project managers,39,There is a strong relationship between general optimism scores and the optimism of performance predictions.,Descriptive statistics; Correlation.,"Mismatched Design and Context (small sample size, aftificial experiment)",14,5,1
Jørgensen,2007,Individual Differences in How Much People are Affected by Irrelevant and Misleading Information,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gxqbS9AAAAAJ&cstart=100&pagesize=100&citation_for_view=gxqbS9AAAAAJ:zCSUwVk65WsC,Individual differences in susceptibility to irrelevant and misleading information in judgment tasks.,To test the hypothesis that mixed-handedness correlates with a greater effect from irrelevant and misleading information in software engineering contexts.,Quasi-Experiment,Between-subjects,Project level,Anchoring; Hindsight Bias; Wishful Thinking,Estimated time; Estimated failure rate; Belief ratings,5,7-17,2-4,Anchor Values; outcome info; framing; wishful thinking; sequence,N/A,,CS Students; Professionals,291,Mixed-handed software engineers will be more affected by irrelevant and misleading information than strong-handed ones.,Descriptive statistics (median comparison).,Mismatched Design and Context (small sample size) Invalid Proxies (Handedness) Incorrect Data Analysis (Lack of tests),14,4,1
Jørgensen,2009,Identiﬁcation of more risks can lead to increased over-optimism of and over-conﬁdence in software development effort estimates,https://doi.org/10.1016/j.infsof.2009.12.002,The effect of risk identification on software development effort estimation.,To test the hypothesis that identifying more risks can counter-intuitively increase over-optimism and over-confidence.,Controlled,Between-subjects,Project level,Over-optimism; Over-confidence,Effort estimate; success probability,4,14-26,2,Less Risks vs. More Risks,N/A,,Professional software developers; Project Managers,180,Identification of more risks leads to more over-optimistic effort estimates and higher over-confidence in project success.,Kruskal–Wallis test (non-parametric).,"Mismatched Design and Context (Artificial experiment, time pressure)",16,8,2
Jørgensen,2012,Software Development Estimation Biases: The Role of Interdependence,https://doi.org/10.1109/TSE.2011.40,Software development effort estimation; interdependence and anchoring.,"To examine how task interdependence and customer expectations (anchors) bias effort estimates, and if competence moderates this.",Controlled Experiment,Between-subjects,Task level,Anchoring; Sequence Effect,Effort estimate in work-hours,2,31-35,2-3,"Anchors (Low, High, None), Sequence",Large,Cohen's d,Software professionals (Vietnam),164,Customer expectations bias estimates; Competence reduces anchoring; Interdependence creates inverse sequence effects.,ANOVA; t-test,None,18,5,1
Jørgensen,2019,Sequence effects in the estimation of software development effort,https://doi.org/10.1016/j.jss.2019.110448,Software development effort estimation; sequence effects (judgments affected by previous judgments).,To examine how the sequence in which tasks are estimated affects judgment-based effort estimates assimilation,Controlled,Within-subjects,Task level,Sequence Effect,Estimated effort (log),2,"104, 362","3,9",Randomized task sequences (Similar sized tasks vs. Differently sized tasks),N/A,,"Software professionals (East-EU, Asia)",466,Contrast effect increases estimates after similarly sized tasks; Assimilation effect pulls estimates toward previous task size for different sized tasks; Competence moderates these effects.,Linear Mixed Models (LMM) with log-transformed dependent variables.,None,17,6,1
Koval,2022,Do You See What You Mean? Using Predictive Visualizations to Reduce Optimism in Duration Estimates,https://doi.org/10.1145/3491102.3502010,Using visualizations to de-bias duration estimates for everyday tasks.,Test if predictive visualizations reduce optimistic bias in task duration estimates.,Controlled,Between-subjects,Project level,Over-optimism,Estimate; Interval coverage; outcomes,2,36,4,"Visualisation(20/50), Feedback(interactive/ chart)",Large,"95% CI [48%, 100%]",Crowdsourced,145,Visualizations will prompt less optimistic estimates; feedback will improve decisions.,Estimation statistics with 95% BCa bootstrap confidence intervals.,"Mismatched Design and Context (demand characteristics, unbalanced design",17,9,1
Løhre,2014,Numerical anchors and their strong effects on software development effort estimates,https://doi.org/10.1016/j.jss.2015.03.015,The effect of numerical anchors on software development effort estimation.,To examine if the numerical precision and source credibility of an anchor can moderate (reduce) the anchoring effect.,Controlled,Between-subjects,Project level,Anchoring,"Likely effort, minimum effort, maximum effrrt; interval width",3,69-130,3-5,Anchor percision; source credability,Medium to Large,η2p = .181,Professional software developers,381,Lower anchor precision and lower source credibility will reduce the anchoring effect.,"ANOVA, Tukey post-hoc comparisons, Chi-square tests, Confidence Intervals.",None,17,6,1
Moløkken,2003,Software Effort Estimation: Unstructured Group Discussion as a Method to Reduce Individual Biases,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gxqbS9AAAAAJ&cstart=100&pagesize=100&citation_for_view=gxqbS9AAAAAJ:QIV2ME_5wuYC,Combining expert judgments to reduce individual bias in software effort estimation.,To test if unstructured group discussion can reduce the optimistic bias found in individual expert estimates.,Controlled,Between-subjects,Project level,Over-optimism,Effort estimate in work-hours,1,4,2,Individual vs. Group discussion,Large,"cohen's d (0.62,1.25)",Experienced developers,20,Group estimates are less optimistic than the average of individual estimates; individuals become less optimistic after group discussion.,Paired t-test.,"Mismatched Design and Context (small sample size, one project)",17,4,0
Moløkken,2004,Group Processes in Software Effort Estimation,https://doi.org/10.1023/B:EMSE.0000039882.39206.5a,Combining expert judgments in software effort estimation.,To determine if unstructured group discussion reduces the optimistic bias found in individual expert estimates.,Controlled,Between-subjects,Project level,Over-optimism,Effort estimate in work-hours,1,4,2,Individual vs. Group discussion,Large,"cohen's d (0.62,1.25)",Experienced developers,20,Group estimates are less optimistic than the average of individual estimates; individuals become less optimistic after group discussion.,Paired t-test.,"Mismatched Design and Context (small sample size, one project)",16,4,0
Moløkken,2005,Expert Estimation of Web-Development Projects: Are Software Professionals in Technical Roles More Optimistic Than Those in Non-Technical Roles?,https://doi.org/10.1023/B:EMSE.0000048321.46871.2e,Expert estimation in web-development projects.,To test if professionals in technical roles provide more optimistic (lower) effort estimates than those in non-technical roles.,Controlled,Between-subjects,Project level,Over-optimism,Likely effort hours,1,10,2,Technical vs. Non-technical,Large,cohen's d (1.1),Experienced developers,20,Experts in technical roles provide more optimistic effort estimates than experts in non-technical roles,t-test; Anderson-Darling test; Kruskal-Wallis test,"Mismatched Design and Context (small sample size, one project)",16,3,0
Moløkken,2007,Combining Estimates with Planning Poker – An Empirical Study,https://doi.org/10.1109/ASWEC.2007.15,Combination of expert estimates in an agile software project.,To compare the optimism and accuracy of Planning Poker estimates against mechanical and individual estimation methods.,Controlled,Between-subjects,Project level,Over-optimism; Anchoring,Effort in work-hours; Balanced Relative Error (BRE); BREbias,1,4-6,2,Planning Poker vs. individual estimate,Small,cohen's d (0.16),Professional software developers,10,Group estimates are less optimistic and more accurate than mechanical or individual estimates.,Paired t-test; Kruskal-Wallis test; Pearson correlation.,"Mismatched Design and Context (Small sample size, one task per team)",17,5,0
Shepperd,2018,An Experimental Evaluation of a De-biasing Intervention for Professional Software Developers,https://doi.org/10.1145/3167132.3167293,De-biasing interventions for professional software developers.,Test if a workshop on cognitive biases reduces anchoring bias in productivity estimates.,Controlled,Between-subjects,Project level,Anchoring,Estimated productivity,2,60-150,4,Low vs. High anchor; De-biasing workshop vs. No workshop,Large,robust Cohen’s d = 1.19,Professional software developers,410,The workshop will reduce the anchoring bias,Robust Yuen test; Brown-Forsythe test; Robust 2-way ANOVA,Mismatched Design and Context (Unbalanced design),17,6,1
Shmueli,2016,Can the outside-view approach improve planning decisions?,https://doi.org/10.1111/isj.12091,Software development planning; Planning Fallacy.,"To test if outside-view mechanisms (reference info, consultant role) reduce planning fallacy biases (time underestimation, scope overload, over-requirement).",Controlled Experiment,Between-subjects,Project level,Planning Fallacy (Optimism Bias),Time estimation (hours); Feature count,1,18-19,4,Role (Dev/Consultant); Reference Info (Yes/No),N/A,,Undergraduate students,75,Reference info reduces bias; Consultant role (observer) reduces bias compared to developer (actor).,ANOVA; MANOVA,"Mismatched Design and Context (Students, Toy Tasks)",16,7,0
Svensson,2021,Is it possible to disregard obsolete requirements? a family of experiments in software effort estimation,https://doi.org/10.48550/arXiv.2103.13265,SEE with obsolete requirements,Test if obsolete requirements imact effort estimates,Controlled,Between-subjects,Task level,Anchoring,"Effort in weeks, Effort in hours",6,20-50,3,"Base, Base + extra, Base + obsolete",Very Large,R² .54-.75,Students/ Professionals,461,Obsolete requiremetns increase estimates,Bayesean analysis; R^2,Mismatched Design and Context (Uneven groups),12,7,3